{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8LmF1GL2kx8"
      },
      "source": [
        "# Project #1 -  Information Retrieval\n",
        "\n",
        "\n",
        "Cory Randolph\n",
        "\n",
        "9/10/2022\n",
        "\n",
        "CMPE 297\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkWUBadhHfGN"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyrS7tMnHhaH"
      },
      "source": [
        "Download the data from the CMU [link](http://www.cs.cmu.edu/~ark/QA-data/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUXKUK3-Fdkn",
        "outputId": "544f64a4-36f8-41f9-a0a3-2b41cf26ed68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: wget\n"
          ]
        }
      ],
      "source": [
        "!wget http://www.cs.cmu.edu/~ark/QA-data/data/Question_Answer_Dataset_v1.2.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il5SCy5UIGXv"
      },
      "source": [
        "Extract the contents of the zipped file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L44yiuAIHfX",
        "outputId": "6451fdf4-7caf-4ac9-805d-ca991bcc7106"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Something went wrong and the CMU data was not unzipped\n"
          ]
        }
      ],
      "source": [
        "# Define the file name and run the unzip command\n",
        "data_file_name = \"Question_Answer_Dataset_v1.2.tar.gz\"\n",
        "!sudo tar -xvf $data_file_name\n",
        "\n",
        "# Clear output for this cell\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "\n",
        "# Display success message if unziped folder exists\n",
        "from pathlib import Path\n",
        "data_file_path = Path(\"/content/Question_Answer_Dataset_v1.2\")\n",
        "if data_file_path.is_dir():\n",
        "  print(\"Successfully Unzipped CMU Data\")\n",
        "else:\n",
        "  print(\"Something went wrong and the CMU data was not unzipped\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_PNQB5yOYdw"
      },
      "source": [
        "# Clean Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SdPfQNZUv11"
      },
      "source": [
        "## Question Answer Pair Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlhRI8hvOaW_"
      },
      "source": [
        "First load in the data as a pandas dataframe for the questions and answers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iVU02KKbIHdA"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
          ]
        }
      ],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwKYxIFbOptz"
      },
      "outputs": [],
      "source": [
        "df_qa_pairs_s08 = pd.read_csv(\"/content/Question_Answer_Dataset_v1.2/S08/question_answer_pairs.txt\", sep=\"\\t\", encoding= \"ISO-8859-1\")\n",
        "df_qa_pairs_s09 = pd.read_csv(\"/content/Question_Answer_Dataset_v1.2/S09/question_answer_pairs.txt\", sep=\"\\t\", encoding= \"ISO-8859-1\")\n",
        "df_qa_pairs_s10 = pd.read_csv(\"/content/Question_Answer_Dataset_v1.2/S10/question_answer_pairs.txt\", sep=\"\\t\", encoding= \"ISO-8859-1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnp3cf25SHvU"
      },
      "source": [
        "Add a column to each question and answer pair dataframe so indicate which dataset it came from (i.e. S08, S09, S10)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLrfULlGIHUr"
      },
      "outputs": [],
      "source": [
        "df_qa_pairs_s08.insert(0, 'Dataset', \"S08\")\n",
        "df_qa_pairs_s09.insert(0, 'Dataset', \"S09\")\n",
        "df_qa_pairs_s10.insert(0, 'Dataset', \"S10\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "B1x6Y8-jIHSE",
        "outputId": "74f54a65-e313-48fd-ac08-eeee33aa3625"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-19236942-e05c-4b54-a24a-5d39cfc7c152\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>ArticleTitle</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>DifficultyFromQuestioner</th>\n",
              "      <th>DifficultyFromAnswerer</th>\n",
              "      <th>ArticleFile</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>S08</td>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Was Abraham Lincoln the sixteenth President of...</td>\n",
              "      <td>yes</td>\n",
              "      <td>easy</td>\n",
              "      <td>easy</td>\n",
              "      <td>data/set3/a4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>S08</td>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Was Abraham Lincoln the sixteenth President of...</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>easy</td>\n",
              "      <td>easy</td>\n",
              "      <td>data/set3/a4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>S08</td>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Did Lincoln sign the National Banking Act of 1...</td>\n",
              "      <td>yes</td>\n",
              "      <td>easy</td>\n",
              "      <td>medium</td>\n",
              "      <td>data/set3/a4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19236942-e05c-4b54-a24a-5d39cfc7c152')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-19236942-e05c-4b54-a24a-5d39cfc7c152 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-19236942-e05c-4b54-a24a-5d39cfc7c152');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  Dataset     ArticleTitle                                           Question  \\\n",
              "0     S08  Abraham_Lincoln  Was Abraham Lincoln the sixteenth President of...   \n",
              "1     S08  Abraham_Lincoln  Was Abraham Lincoln the sixteenth President of...   \n",
              "2     S08  Abraham_Lincoln  Did Lincoln sign the National Banking Act of 1...   \n",
              "\n",
              "  Answer DifficultyFromQuestioner DifficultyFromAnswerer   ArticleFile  \n",
              "0    yes                     easy                   easy  data/set3/a4  \n",
              "1   Yes.                     easy                   easy  data/set3/a4  \n",
              "2    yes                     easy                 medium  data/set3/a4  "
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_qa_pairs_s08.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4C0gvuMTgeg"
      },
      "source": [
        "Combine all of them into one dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPYLMRLjIHPe",
        "outputId": "a960692a-62b6-492f-e7ad-4bd3a4141aee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 3998 entries, 0 to 1457\n",
            "Data columns (total 7 columns):\n",
            " #   Column                    Non-Null Count  Dtype \n",
            "---  ------                    --------------  ----- \n",
            " 0   Dataset                   3998 non-null   object\n",
            " 1   ArticleTitle              3998 non-null   object\n",
            " 2   Question                  3961 non-null   object\n",
            " 3   Answer                    3422 non-null   object\n",
            " 4   DifficultyFromQuestioner  3043 non-null   object\n",
            " 5   DifficultyFromAnswerer    3418 non-null   object\n",
            " 6   ArticleFile               3996 non-null   object\n",
            "dtypes: object(7)\n",
            "memory usage: 249.9+ KB\n"
          ]
        }
      ],
      "source": [
        "df_qa_pairs = df_qa_pairs_s08.append([df_qa_pairs_s09, df_qa_pairs_s10])\n",
        "df_qa_pairs.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KJoCdCVYi29"
      },
      "source": [
        "Clean up this data by removing rows that have missing Questions, Answers, or Article Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ln4iL9v8YsMW"
      },
      "outputs": [],
      "source": [
        "df_qa_pairs = df_qa_pairs.dropna(subset=['Question', 'Answer', 'ArticleFile'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ3H7KK-ZS_2"
      },
      "source": [
        "Next drow rows where the Question, Answer, and ArticleFile are the same values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PqrRX4nZhtA"
      },
      "outputs": [],
      "source": [
        "df_qa_pairs = df_qa_pairs.drop_duplicates(subset=['Question', 'Answer', 'ArticleFile'], keep='first')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnWyowxadI9Q"
      },
      "source": [
        "Create a modified ArticleFile column that adds in the extra path information from these local Colab files so that they can be matched from the custom information retrieval system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdWmRbPVeSCa"
      },
      "outputs": [],
      "source": [
        "df_qa_pairs[\"ArticleFileCustom\"] = df_qa_pairs.apply(lambda row: f\"/content/Question_Answer_Dataset_v1.2/{row['Dataset']}/{row['ArticleFile']}.txt\", axis =1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "gEtxgHRBfxpO",
        "outputId": "96d87e95-675f-4647-ec63-df3724bba3f7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-259d25ae-d82d-495f-a687-742e2e7d5377\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ArticleFile</th>\n",
              "      <th>ArticleFileCustom</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>data/set3/a4</td>\n",
              "      <td>/content/Question_Answer_Dataset_v1.2/S08/data...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>data/set3/a4</td>\n",
              "      <td>/content/Question_Answer_Dataset_v1.2/S08/data...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>data/set3/a4</td>\n",
              "      <td>/content/Question_Answer_Dataset_v1.2/S08/data...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-259d25ae-d82d-495f-a687-742e2e7d5377')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-259d25ae-d82d-495f-a687-742e2e7d5377 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-259d25ae-d82d-495f-a687-742e2e7d5377');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    ArticleFile                                  ArticleFileCustom\n",
              "0  data/set3/a4  /content/Question_Answer_Dataset_v1.2/S08/data...\n",
              "1  data/set3/a4  /content/Question_Answer_Dataset_v1.2/S08/data...\n",
              "2  data/set3/a4  /content/Question_Answer_Dataset_v1.2/S08/data..."
            ]
          },
          "execution_count": 160,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_qa_pairs[[\"ArticleFile\",\"ArticleFileCustom\"]].head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKd5V84ttysA"
      },
      "source": [
        "Combine the rows where the question is the same but the referenced article is different between the two answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTRJXYmbxWFO",
        "outputId": "8e78c767-fb45-4614-8a97-c88236f7b01e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Dataset', 'ArticleTitle', 'Question', 'Answer',\n",
              "       'DifficultyFromQuestioner', 'DifficultyFromAnswerer', 'ArticleFile',\n",
              "       'ArticleFileCustom'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 161,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_qa_pairs.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvNiwuo6Xr_q"
      },
      "outputs": [],
      "source": [
        "def create_combined_article_files(df_qa_pairs: pd.DataFrame):\n",
        "  # Find any questions that have multiple files with the correct answer and\n",
        "  # combine them into a new column with a comma separating them\n",
        "  df_temp_01 = df_qa_pairs.copy()\n",
        "  df_temp_01 = df_temp_01[[\"Question\", \"ArticleFileCustom\"]]\n",
        "  df_temp_01 = df_temp_01.drop_duplicates(subset=[\"Question\", \"ArticleFileCustom\"])\n",
        "  df_temp_01[\"ArticleFilesCustom\"] = df_temp_01[[\"Question\", \"ArticleFileCustom\"]].groupby([\"Question\"])[\"ArticleFileCustom\"].transform(lambda x: \",\".join(x))\n",
        "  df_temp_01 = df_temp_01[[\"Question\", \"ArticleFilesCustom\"]].drop_duplicates()\n",
        "\n",
        "  # Add the combined column as a new column\n",
        "  df_temp_02 = df_qa_pairs.copy()\n",
        "  df_temp_02 = df_temp_02.merge(df_temp_01, how=\"left\", on = \"Question\")\n",
        "  df_temp_02 = df_temp_02.drop([\"ArticleFileCustom\"], axis=1)\n",
        "  \n",
        "  return df_temp_02"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWlIzoYyYk6H"
      },
      "outputs": [],
      "source": [
        "df_qa_pairs = create_combined_article_files(df_qa_pairs = df_qa_pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oP6u-3wAaHfa"
      },
      "source": [
        "Show the summary infor after cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOWrHgaeaKba",
        "outputId": "ef6fa37e-6564-428f-a6c4-9a948a3c13e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 3111 entries, 0 to 3110\n",
            "Data columns (total 8 columns):\n",
            " #   Column                    Non-Null Count  Dtype \n",
            "---  ------                    --------------  ----- \n",
            " 0   Dataset                   3111 non-null   object\n",
            " 1   ArticleTitle              3111 non-null   object\n",
            " 2   Question                  3111 non-null   object\n",
            " 3   Answer                    3111 non-null   object\n",
            " 4   DifficultyFromQuestioner  2429 non-null   object\n",
            " 5   DifficultyFromAnswerer    3108 non-null   object\n",
            " 6   ArticleFile               3111 non-null   object\n",
            " 7   ArticleFilesCustom        3111 non-null   object\n",
            "dtypes: object(8)\n",
            "memory usage: 218.7+ KB\n"
          ]
        }
      ],
      "source": [
        "df_qa_pairs.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHyD7kgtqP1o"
      },
      "source": [
        "# TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xa-rLIUqkmF"
      },
      "source": [
        "Implement TF-IDF for the various datasets in order to find the most appropriate documents based on a given query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfozbBPPIHMm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2E3IH_cnJls"
      },
      "source": [
        "## Create Corpus\n",
        "Create a doctionary that holds the corpus and the file name and the text of the document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFbMKCLHu5RC"
      },
      "outputs": [],
      "source": [
        "def create_document_paths() -> list:\n",
        "  from pathlib import Path\n",
        "  \n",
        "  # Root directory name\n",
        "  dirname = '/content/Question_Answer_Dataset_v1.2'\n",
        "  \n",
        "  # Provide directory name to Path() function and pattern for finding \n",
        "  # the answer files that match \"a\" and end in \".txt\"\n",
        "  paths = Path(dirname).glob('**/a*.txt',)\n",
        "  \n",
        "  # Iterate over all answer files\n",
        "  document_paths = []\n",
        "  for path in paths:\n",
        "    document_paths.append(str(path))\n",
        "    # print(path)  # Print file name\n",
        "\n",
        "  # Sort the paths for repeatability \n",
        "  document_paths = sorted(document_paths)\n",
        "\n",
        "  return document_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAVT2WQSwgde"
      },
      "outputs": [],
      "source": [
        "document_paths = create_document_paths()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMTgNrM8kgdm"
      },
      "source": [
        "Display the total number of documents in this corpus (i.e. the number of document paths we have"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOrzOdrJknBI",
        "outputId": "cdc753d4-299f-460d-9f65-6eacced5853f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "execution_count": 263,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(document_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-a7e2d8wI6H"
      },
      "source": [
        "Display 5 sample documents paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g955GXjIbfdx",
        "outputId": "5ed79fc0-3909-4c06-f2e3-ad620da94353"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/Question_Answer_Dataset_v1.2/S08/data/set4/a1.txt',\n",
              " '/content/Question_Answer_Dataset_v1.2/S08/data/set4/a2.txt',\n",
              " '/content/Question_Answer_Dataset_v1.2/S08/data/set4/a3.txt',\n",
              " '/content/Question_Answer_Dataset_v1.2/S08/data/set4/a4.txt',\n",
              " '/content/Question_Answer_Dataset_v1.2/S08/data/set4/a5.txt']"
            ]
          },
          "execution_count": 264,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "document_paths_sample = ['/content/Question_Answer_Dataset_v1.2/S08/data/set4/a1.txt',\n",
        "  '/content/Question_Answer_Dataset_v1.2/S08/data/set4/a2.txt',\n",
        "  '/content/Question_Answer_Dataset_v1.2/S08/data/set4/a3.txt',\n",
        "  '/content/Question_Answer_Dataset_v1.2/S08/data/set4/a4.txt',\n",
        "  '/content/Question_Answer_Dataset_v1.2/S08/data/set4/a5.txt'\n",
        " ]\n",
        "\n",
        "document_paths_sample\n",
        "\n",
        "#  First 5 unnamed docs:\n",
        "# document_paths_sample = document_paths[:5]\n",
        "# document_paths_sample "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDbBKl4pxFmm"
      },
      "source": [
        "Create a corpus of all the documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bl82-zwdC3ij"
      },
      "outputs": [],
      "source": [
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QpMUpAtnah7"
      },
      "outputs": [],
      "source": [
        "def create_corpus(document_paths: list):\n",
        "  corpus = {}\n",
        "\n",
        "  \"\"\"Limiting to the first 5 for initial testing, Change to all documents later\"\"\"\n",
        "  for document_path in document_paths:\n",
        "    with io.open(f'{document_path}','r', encoding=\"latin-1\") as document:\n",
        "      corpus[document_path] = document.read()\n",
        "\n",
        "  return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvStkQyxw9jd"
      },
      "outputs": [],
      "source": [
        "corpus_sample = create_corpus(document_paths = document_paths_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrV02fXwp1tv"
      },
      "source": [
        "Display an example of a document path and document text form the corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHDQci1GxwCe",
        "outputId": "55674832-a0c1-41c8-b966-9e59e1360d21"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['/content/Question_Answer_Dataset_v1.2/S08/data/set4/a1.txt', '/content/Question_Answer_Dataset_v1.2/S08/data/set4/a2.txt', '/content/Question_Answer_Dataset_v1.2/S08/data/set4/a3.txt', '/content/Question_Answer_Dataset_v1.2/S08/data/set4/a4.txt', '/content/Question_Answer_Dataset_v1.2/S08/data/set4/a5.txt'])"
            ]
          },
          "execution_count": 173,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Keys in the corpus are the files paths\n",
        "corpus_sample.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jAimxubdz6NB",
        "outputId": "64926827-d39f-4e7c-94b0-22a161925cc5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/Question_Answer_Dataset_v1.2/S08/data/set4/a1.txt'"
            ]
          },
          "execution_count": 174,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example of the first 300 characters of one of the documents\n",
        "first_doc_path_sample :str = list(corpus_sample.keys())[0]\n",
        "first_doc_path_sample\n",
        "# corpus_sample[first_doc_path_sample][:300]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbsPRisJ0tmU"
      },
      "source": [
        "Create a single sample document that can be used for testing and development"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eeo75nBo3XG"
      },
      "outputs": [],
      "source": [
        "# Create a sample document that is just a single string\n",
        "document_sample :str = corpus_sample[first_doc_path_sample]\n",
        "# document_sample # Uncomment to display the full text of document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64_cKqGGp1WV"
      },
      "source": [
        "## Tokenize Document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4J9_quZp9-U"
      },
      "source": [
        "Create a custom tokenizer that will take the document as input and then break it up into a list of tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_CJ1Odwf4tS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRIUNFaRZ3bH"
      },
      "outputs": [],
      "source": [
        "def custom_tokenizer(document: str) -> list:\n",
        "  \"\"\"\n",
        "  Create a custom tokenizer function. This should allow us to modify\n",
        "  the tokenizer for experiments while keeping the rest of the processing\n",
        "  pipeline the same.\n",
        "\n",
        "  Note: Using Numpy arrays for faster performance over python lists\n",
        "  \"\"\"\n",
        "  # Clean document (Note: We may want to keep the periods or new lines for forming sentences later)\n",
        "  document = document.lower() # Lower case all letters\n",
        "  document = re.sub(r'[^a-z0-9\\s]',' ',document) # Remove all non letter, non-number and non space characters\n",
        "  document = re.sub(r'\\n',' ',document) # Remove line breaks\n",
        "  document = re.sub(r'\\s+',' ',document) # Remove Extra spaces\n",
        "\n",
        "\n",
        "  # Split the sentence into words based on the space\n",
        "  tokens = document.split()\n",
        "\n",
        "  # Make sure each token doesn't have extra spaces on the ends\n",
        "  tokens = [token.strip() for token in tokens]\n",
        "\n",
        "  # Drop Stop words:\n",
        "  # TODO:\n",
        "\n",
        "  # Drop single letters (loose \"I\" and \"a\", but those are potentially stop word anyways)\n",
        "  tokens = [token for token in tokens if len(token) > 1]\n",
        "\n",
        "  # Turn the list into a numpy array for performance\n",
        "  tokens = np.array(tokens)\n",
        "\n",
        "  # Maybe add limitation to make sure the words are english characters/words (in nltk this is .alpha())\n",
        "  # TODO:\n",
        "\n",
        "  return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "96X9YwLftIZ9",
        "outputId": "2481e456-be68-43d1-80c0-2780e0477423"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Isaac Newton\\n\\n\\n\\nSir Isaac Newton FRS ( ) (4 January 1643 â\\x80\\x93 March 31 1727)   [  OS: December 25 1642 â\\x80\\x93 March 20 1727 ]    was an English physicist, mathematician, astronomer, natural philosopher, and alchemist. His treatise PhilosophiÃ¦ Naturalis Principia Mathematica, published in 1687, describe'"
            ]
          },
          "execution_count": 178,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "document_sample[:300]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsTDgimW244Y"
      },
      "source": [
        "Apply the custom tokenizer to the sample document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgL7jGWIpVfy",
        "outputId": "82568dbf-cf6b-45d0-ab88-f878a7b4afcb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['isaac', 'newton', 'sir', 'isaac', 'newton', 'frs', 'january',\n",
              "       '1643', 'march', '31', '1727', 'os', 'december', '25', '1642',\n",
              "       'march', '20', '1727', 'was', 'an'], dtype='<U15')"
            ]
          },
          "execution_count": 179,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "custom_tokenizer(document_sample)[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni4TTpZZ4HRK"
      },
      "source": [
        "Apply the tokenizer to the corpus. This will convert the string documents into lists of tokens/words in the document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUEJKrAmpJ65"
      },
      "outputs": [],
      "source": [
        "def tokenize_corpus(corpus: dict, tokenizer):\n",
        "  corpus_tokenized = {}\n",
        "  # Itterate through each document in the corpus and apply the custom tokenizer\n",
        "  for document_path, document in corpus.items():\n",
        "    # corpus[document_path] = [token for token in custom_tokenizer(corpus[document_path])]\n",
        "    corpus_tokenized[document_path] = custom_tokenizer(document)\n",
        "\n",
        "  return corpus_tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLNI4n6u4G-U"
      },
      "outputs": [],
      "source": [
        "corpus_tokenized_sample = tokenize_corpus(corpus = corpus_sample, tokenizer = custom_tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdBtMb6s6BRJ"
      },
      "source": [
        "Create a single sample of a corpus document with the file path and document in it's tokenized form"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3vJ5E365_8N",
        "outputId": "0b5252f9-d743-467f-ffa1-94e0c2a7be59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['isaac', 'newton', 'sir', 'isaac', 'newton', 'frs', 'january',\n",
              "       '1643', 'march', '31', '1727', 'os', 'december', '25', '1642'],\n",
              "      dtype='<U15')"
            ]
          },
          "execution_count": 182,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Note the corpus_document_sample is a dictionary with one item in the form of {file_path: document as a list}\n",
        "# document_tokenized_sample :dict = {first_doc_path_sample:corpus_tokenized_sample[first_doc_path_sample]}\n",
        "\n",
        "# Create a sample document that is a list of the tokens form one document\n",
        "document_tokenized_sample = corpus_tokenized_sample[first_doc_path_sample]\n",
        "document_tokenized_sample[:15]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mNH8c5Z3JAQ"
      },
      "source": [
        "## Create Vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KpIk_l83Pla"
      },
      "source": [
        "Iterate through all of the documents and create a vocabulary on unique words found."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYzmqdGKpqGo"
      },
      "outputs": [],
      "source": [
        "def create_vocabulary(corpus : dict):\n",
        "  # Add every word in the corpus to a set of vocabualry words\n",
        "  vocabulary = np.empty(0)\n",
        "  for document in corpus.values():\n",
        "    # Add Each document to the vocabulary\n",
        "    vocabulary = np.append(vocabulary,document)\n",
        "\n",
        "  # Get just the unique values\n",
        "  vocabulary = np.unique(vocabulary)\n",
        "\n",
        "  # Convert the set into a sorted list\n",
        "  vocabulary = np.sort(vocabulary)\n",
        "\n",
        "  return vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxzrJ6c5IHGF"
      },
      "outputs": [],
      "source": [
        "vocabulary_sample = create_vocabulary(corpus_tokenized_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKCMzxP7IGyT",
        "outputId": "7aebe5d7-7c89-47c4-bfb0-216cc3374186"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5555"
            ]
          },
          "execution_count": 185,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(vocabulary_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVtnXf455YcW"
      },
      "source": [
        "Display the first few words in the vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18qqm7LVUFug",
        "outputId": "1bde6f38-2e41-42f3-c61b-76eb1822a10c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['000', '00189', '0028', '008', '01', '04', '045', '05',\n",
              "       '0688168949', '0743215362', '0760710058', '082', '08817',\n",
              "       '0914732334', '10', '100', '100rsd', '101', '103', '104'],\n",
              "      dtype='<U32')"
            ]
          },
          "execution_count": 186,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocabulary_sample[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyJAS0gF5jwE"
      },
      "source": [
        "Note: After looking through this there are many additional ways to clean up these tokens such as removing white space, non letter characters, non-english characters, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh0_faK70dBk"
      },
      "source": [
        "# Try breasking the calclualtions up to speed up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoXeqaIk6q4E"
      },
      "source": [
        "## Calculate Term Frequency (TF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDd43oQo6wYh"
      },
      "source": [
        "Iterate over all of the document_paths in the corpus and calculate the frequency that the terms appea in each document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylx85-wEqQOu"
      },
      "outputs": [],
      "source": [
        "def calculate_term_frequency(corpus: dict, vocabulary: set):\n",
        "  # Create a term frequency for every document in the corpus\n",
        "  tf = {}\n",
        "\n",
        "  for document_path in corpus:\n",
        "    tf[document_path] = {word: np.count_nonzero(corpus[document_path] == word) / len(corpus[document_path]) for word in vocabulary}\n",
        "    # tf[document_path] = {word: corpus[document_path].count(word) for word in vocabulary}\n",
        "\n",
        "  return tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfLU5yMiUFsc"
      },
      "outputs": [],
      "source": [
        "tf_sample = calculate_term_frequency(corpus = corpus_tokenized_sample, vocabulary = vocabulary_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STt_aQqw8Cn1"
      },
      "source": [
        "Display the first few example of the term frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CzMxmXyUFp4",
        "outputId": "8c523a26-9814-4c34-8293-c34ca0fedf47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('000', 0.0),\n",
              " ('00189', 0.00015997440409534473),\n",
              " ('0028', 0.0),\n",
              " ('008', 0.0),\n",
              " ('01', 0.0),\n",
              " ('04', 0.0),\n",
              " ('045', 0.0),\n",
              " ('05', 0.0),\n",
              " ('0688168949', 0.0),\n",
              " ('0743215362', 0.0),\n",
              " ('0760710058', 0.0),\n",
              " ('082', 0.0),\n",
              " ('08817', 0.00015997440409534473),\n",
              " ('0914732334', 0.0),\n",
              " ('10', 0.0)]"
            ]
          },
          "execution_count": 209,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(tf_sample[first_doc_path_sample].items())[:15]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwW6LNYl9CvO"
      },
      "source": [
        "## Calculate Inverse Document Frequency (IDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcqctJsF9NbB"
      },
      "source": [
        "Iterate through all of the words in the vocabulary and calculate how many documents it's in from the corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZR_pL6Tq2Ax"
      },
      "outputs": [],
      "source": [
        "def calculate_inverse_document_frequency(corpus :dict, vocabulary: np.array):\n",
        "  # For every word in the vocabulay calcualte the inverse frequency\n",
        "  idf = {}\n",
        "\n",
        "  for word in vocabulary:\n",
        "    # freq = np.sum(word in corpus[document_path] for document_path in corpus)\n",
        "    freq = (sum([1 for doc in corpus.values() if word in doc]) + 1)\n",
        "    idf[word] = np.log10(len(corpus) / freq)\n",
        "\n",
        "  return idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fwwce8ubUFne"
      },
      "outputs": [],
      "source": [
        "idf_sample = calculate_inverse_document_frequency(corpus = corpus_tokenized_sample, vocabulary = vocabulary_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRVKqImj9288"
      },
      "source": [
        "Display the first few examples of the Inverse Document Frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsjHJqUq9289",
        "outputId": "93c941e2-c42f-40b9-e220-cecba450bd0b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('cancer', 0.3979400086720376),\n",
              " ('cannon', 0.3979400086720376),\n",
              " ('cannonball', 0.3979400086720376),\n",
              " ('cannot', 0.22184874961635637),\n",
              " ('capable', 0.3979400086720376),\n",
              " ('caparica', 0.3979400086720376),\n",
              " ('capital', 0.09691001300805642),\n",
              " ('captain', 0.3979400086720376),\n",
              " ('caption', 0.3979400086720376),\n",
              " ('car', 0.3979400086720376),\n",
              " ('cardinal', 0.3979400086720376),\n",
              " ('care', 0.22184874961635637),\n",
              " ('careful', 0.3979400086720376),\n",
              " ('carefully', 0.3979400086720376),\n",
              " ('carlson', 0.3979400086720376)]"
            ]
          },
          "execution_count": 215,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(idf_sample.items())[1000:1015]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgptvOao_Vyk"
      },
      "source": [
        "## Calculate Term Frequence-Inverse Document Frequency (TF-IDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQBt9VsP_Vyk"
      },
      "source": [
        "Iterate through every document in the corpus and then multiply the Term Frequency (TF) with the Inter Document Frequency (IDF). Store this in a dictionary with the document path as the key and the vocabulary-base vector ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBbQ1II2_UTp"
      },
      "outputs": [],
      "source": [
        "def calculate_tfidf(tf: dict, idf: dict):\n",
        "  tfidf = {}\n",
        "\n",
        "  # Since the tf and idf are already in order and based on the vocabulary\n",
        "  # we can convert them to numpy arrays and multiple\n",
        "  idf_array = np.array(list(idf.values()))\n",
        "\n",
        "  for document_path in tf:\n",
        "    # Convert the tf values into a numpy array\n",
        "    tf_array = np.array(list(tf[document_path].values()))\n",
        "\n",
        "    tfidf[document_path] = np.multiply(tf_array,idf_array)\n",
        "\n",
        "  return tfidf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeh4Fg0WEIRw"
      },
      "outputs": [],
      "source": [
        "tfidf_sample = calculate_tfidf( tf = tf_sample, idf = idf_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kwc0BZ7Gtci"
      },
      "source": [
        "Display Sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHUGDge3EIPn",
        "outputId": "77b94bef-b53f-4e8e-ed2d-f67926daaeca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.00000000e+00, 6.36602158e-05, 0.00000000e+00, ...,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
            ]
          },
          "execution_count": 266,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_sample[first_doc_path_sample]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeJEWhCFeVM-"
      },
      "source": [
        "## Calculate Term Frequence-Inverse Document Frequency (TF-IDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwOrxnUReVM-"
      },
      "source": [
        "Iterate through every document in the corpus and then multiply the Term Frequency (TF) with the Inter Document Frequency (IDF). Store this in a dictionary with the document path as the key and the vocabulary-base vector ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiXckRRReeNN"
      },
      "outputs": [],
      "source": [
        "# def calculate_tfidf(corpus:dict, document: np.array, word: str ):\n",
        "#   # Calculate TF\n",
        "#   # tf = document.count(word) /len(document)\n",
        "#   tf = np.count_nonzero(document == word) /len(document)\n",
        "#   # tf = (document == word).sum() /len(document) \n",
        "\n",
        "#   # Inverse Document Frequency\n",
        "#   idf = np.log10(len(corpus.keys()) / (sum([1 for doc in corpus.values() if word in doc]) + 1))\n",
        "\n",
        "#   # TF-IDF\n",
        "#   tfidf = round(tf*idf,4)\n",
        "  \n",
        "#   return tfidf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6Y3xI4meeNO",
        "outputId": "9d88629f-ff89-4093-ad6e-fa0582d9881b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0015"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# calculate_tfidf(corpus = corpus_tokenized_sample, document = document_tokenized_sample, word = 'isaac')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Mh_U_hEeeNO"
      },
      "source": [
        "Create vector from vocabulary for each document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AV65oBqMeeNO"
      },
      "outputs": [],
      "source": [
        "# def tfidf_for_corpus(corpus: dict, vocabulary: list, print_progress: bool = False):\n",
        "#   tfidf = {}\n",
        "#   document_counter = 0\n",
        "\n",
        "#   # Itterate through each document in the corpus\n",
        "#   for document_path, document in corpus.items():\n",
        "#     # Display progress option for every 10 documents\n",
        "#     if print_progress:\n",
        "#       document_counter =+ 1\n",
        "#       if document_counter % 10 == 0:\n",
        "#         print(f\"Calculating TFIDF for {document_path}\")\n",
        "\n",
        "#     # Create empty list\n",
        "#     cur_document_tfidf = np.zeros(len(vocabulary))\n",
        "\n",
        "#     # Itterate through each word in the vocabulary and calculate TFIDF\n",
        "#     # for word in vocabulary:\n",
        "#     for idx, word in enumerate(vocabulary):\n",
        "#       cur_document_tfidf[idx] = calculate_tfidf(corpus = corpus, document = document, word = word)\n",
        "\n",
        "#     tfidf[document_path] = cur_document_tfidf\n",
        "\n",
        "#   return tfidf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6LVph0ReeNP"
      },
      "outputs": [],
      "source": [
        "# tfidf_sample = tfidf_for_corpus(corpus = corpus_tokenized_sample, vocabulary = vocabulary_sample, print_progress=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP6tznyvwMBb"
      },
      "source": [
        "## Query Based on TF_IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQtjsaRSwMBb"
      },
      "source": [
        "Take an input query and use the generated TF-IDF results to provide a ranked list of matching documents with potential answer to the query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3lBqBZBwMBb"
      },
      "outputs": [],
      "source": [
        "query_sample = \"Is it true that newton saw god as the master creator\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhheNr2wwMBb"
      },
      "source": [
        "Apply the custom tokenizer to the input query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otjWuUg7wMBc",
        "outputId": "ae15a8f9-a155-474c-f865-acbaaf02bc4e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['is', 'it', 'true', 'that', 'newton', 'saw', 'god', 'as', 'the',\n",
              "       'master', 'creator'], dtype='<U7')"
            ]
          },
          "execution_count": 268,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query_tokenized_sample = custom_tokenizer(query_sample)\n",
        "query_tokenized_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GZ4KhaVwMBc",
        "outputId": "dcdfc596-4e8a-4617-bc39-ae867f9e66df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.00000000e+00, 6.36602158e-05, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00])"
            ]
          },
          "execution_count": 269,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_sample[first_doc_path_sample][:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDyGTEaDwz0e"
      },
      "source": [
        "### Cosine Simlarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2mj9oI0wz0f"
      },
      "source": [
        "Apply cosine similarity between the query and each document. Since the tfidf dictionary is already vectorized based on the vocabulary we just need to vectorize the input query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DTf1ZDHwz0g"
      },
      "outputs": [],
      "source": [
        "def vectorize_query(query: str, vocabulary :list, tokenizer: object):\n",
        "  # Tokenize query with custom tokenizer\n",
        "  query_tokenized = tokenizer(query)\n",
        "\n",
        "  # Create a vector of 0's with the vocabulary lenght\n",
        "  query_vector = np.zeros(len(vocabulary))\n",
        "\n",
        "  # Itterate through each word in the vocabulary list\n",
        "  for index, vocab_word in enumerate(vocabulary):\n",
        "    # Set the vector value equal to the tfidf value when ever the words match\n",
        "    for query_word in query_tokenized:\n",
        "      if query_word == vocab_word:\n",
        "        query_vector[index] = 1\n",
        "      else:\n",
        "        pass\n",
        "\n",
        "  return query_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnil8q7Ywz0g"
      },
      "source": [
        "Show example vectorized query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JltVJEUZwz0g",
        "outputId": "c0ba5d88-b528-4c2b-bd68-743aa4718e6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "execution_count": 271,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query_vectorized_sample = vectorize_query(query = query_sample, vocabulary = vocabulary_sample, tokenizer = custom_tokenizer)\n",
        "query_vectorized_sample[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnCh8NaXwz0g"
      },
      "source": [
        "Define Cosine simliarity formula"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwsoDompwz0g"
      },
      "outputs": [],
      "source": [
        "def cosine_sim(vector_a, vector_b):\n",
        "    cosine_sim = np.dot(vector_a, vector_b)/(np.linalg.norm(vector_a)*np.linalg.norm(vector_b))\n",
        "    return cosine_sim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYkCo0Ebwz0h"
      },
      "source": [
        "Example Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60BEOyxJwz0h",
        "outputId": "c682abf7-59ab-46ad-8666-e14898905ffc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.16481043105913037"
            ]
          },
          "execution_count": 273,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cosine_sim(query_vectorized_sample, tfidf_sample[first_doc_path_sample])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8Q-kgYPwz0h"
      },
      "source": [
        "Combine this all to gether to calculate the cosine similarity for all queries and output the ranked document paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jR_t_fhxwz0h"
      },
      "outputs": [],
      "source": [
        "def calculate_query_cosine_similarity_for_all_docs(query: str, tfidf: dict, vocabulary : list, tokenizer: object, n: int):\n",
        "  \"\"\"\n",
        "  Apply the cosine similarity measure for all documents and return the top N results\n",
        "\n",
        "  Input:\n",
        "    n = Top N documents for a given query\n",
        "  \"\"\"\n",
        "  # Vectorize query\n",
        "  query_vectorized = vectorize_query(query, vocabulary, tokenizer)\n",
        "\n",
        "  # Generate score \n",
        "  cosine_similarity_score = []\n",
        "  for document_path, tfidf_vector in tfidf.items():\n",
        "    # Calculate the query similarity\n",
        "    cosine_similarity_score.append([document_path, cosine_sim(query_vectorized, tfidf_vector)])\n",
        "\n",
        "  # Sort scores\n",
        "  cosine_similarity_score_sorted = sorted(cosine_similarity_score, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "  # Return just the top n resutls\n",
        "  top_n_document_paths = [document_path[0] for document_path in cosine_similarity_score_sorted]\n",
        "\n",
        "  # Format the returned results into a comma separated string\n",
        "  top_n_document_paths = \",\".join(top_n_document_paths)\n",
        "\n",
        "  return top_n_document_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "8ekSsZOpwz0h",
        "outputId": "6abaeda3-daba-45be-a49e-a4a6bd5eac6f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/Question_Answer_Dataset_v1.2/S08/data/set4/a1.txt,/content/Question_Answer_Dataset_v1.2/S08/data/set4/a5.txt,/content/Question_Answer_Dataset_v1.2/S08/data/set4/a3.txt,/content/Question_Answer_Dataset_v1.2/S08/data/set4/a2.txt,/content/Question_Answer_Dataset_v1.2/S08/data/set4/a4.txt'"
            ]
          },
          "execution_count": 275,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "calculate_query_cosine_similarity_for_all_docs(query = query_sample, tfidf = tfidf_sample, vocabulary = vocabulary_sample, tokenizer = custom_tokenizer, n = 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmXy6pjVwz0h"
      },
      "source": [
        "Create a final data structure with the document path and the ranked documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dV81rx1_wz0h"
      },
      "outputs": [],
      "source": [
        "example_queries = [\n",
        "    \"Is it true that newton saw god as the master creator\",\n",
        "    \"Who was born precisely at midnight during an electrical storm , to a Serbian family in the village of Smiljan near Gospić\",\n",
        "    \"what was Blaise Pascal famos for\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXZwU5LKwz0i"
      },
      "outputs": [],
      "source": [
        "df_cosine_similarity = pd.DataFrame(example_queries, columns = [\"query\"]) #Substitute actual questiond from docs later"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmEgV8HEwz0i"
      },
      "source": [
        "Add the top n resulting documents that are similar to the query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhUW2_xTwz0i"
      },
      "outputs": [],
      "source": [
        "df_cosine_similarity[\"matching_documents\"] = df_cosine_similarity[\"query\"].apply(lambda query: calculate_query_cosine_similarity_for_all_docs(query = query, tfidf = tfidf_sample, vocabulary = vocabulary_sample, tokenizer = custom_tokenizer, n = 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "s0Ng5i_Pwz0i",
        "outputId": "9e1564d1-bdf1-47f1-ca12-0efee1ad1aff"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b27ff3cd-8377-4059-8cc2-431748500aad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>matching_documents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Is it true that newton saw god as the master c...</td>\n",
              "      <td>/content/Question_Answer_Dataset_v1.2/S08/data...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Who was born precisely at midnight during an e...</td>\n",
              "      <td>/content/Question_Answer_Dataset_v1.2/S08/data...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what was Blaise Pascal famos for</td>\n",
              "      <td>/content/Question_Answer_Dataset_v1.2/S08/data...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b27ff3cd-8377-4059-8cc2-431748500aad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b27ff3cd-8377-4059-8cc2-431748500aad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b27ff3cd-8377-4059-8cc2-431748500aad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               query  \\\n",
              "0  Is it true that newton saw god as the master c...   \n",
              "1  Who was born precisely at midnight during an e...   \n",
              "2                   what was Blaise Pascal famos for   \n",
              "\n",
              "                                  matching_documents  \n",
              "0  /content/Question_Answer_Dataset_v1.2/S08/data...  \n",
              "1  /content/Question_Answer_Dataset_v1.2/S08/data...  \n",
              "2  /content/Question_Answer_Dataset_v1.2/S08/data...  "
            ]
          },
          "execution_count": 279,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_cosine_similarity.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSS9x8nmdL_S"
      },
      "source": [
        "## Save Intermittent Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4yvBGURdL_T"
      },
      "source": [
        "Create a way to save smaller objects as pickle files during the development process, since some functions take ~20 mintures to run on thw whole corpus this will make development time shorter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRq0Y68PdL_T"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKBgr4HLdL_T"
      },
      "outputs": [],
      "source": [
        "def save_as_pickle(object_to_be_saved, file_name):\n",
        "  with open(file_name, 'wb') as handle:\n",
        "      pickle.dump(object_to_be_saved, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "  print(f\"Pickle file has been saved to {file_name}\")\n",
        "  return None\n",
        "\n",
        "def read_pickle(file_name):\n",
        "  with open(file_name, 'rb') as handle:\n",
        "      object_to_be_read = pickle.load(handle)\n",
        "  return object_to_be_read"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psVYrCvQdL_T"
      },
      "outputs": [],
      "source": [
        "# save_as_pickle(corpus, \"corpus_item.pickle\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxiMmbRmdL_T"
      },
      "source": [
        "Add a current time stamp function for file naming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Zf_Cuz1dL_T"
      },
      "outputs": [],
      "source": [
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1TLgexQdL_T"
      },
      "outputs": [],
      "source": [
        "def current_time_stamp():\n",
        "  ts = datetime.datetime.now()\n",
        "  # Convert to string format\n",
        "  ts = ts.strftime(\"%y%m%d_%H_%M_%S\")\n",
        "  return ts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3F9AdwUFdL_U",
        "outputId": "203fad65-8517-4421-bd7b-eeab41ecbe56"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'221005_21_46_12'"
            ]
          },
          "execution_count": 285,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_time_stamp()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxcsARh8dL_U"
      },
      "source": [
        "## Combine to Single Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcNGdHwxdL_U"
      },
      "source": [
        "Use all of the above functions combined into one repeateable function for experimenting with different configurations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VcYtX33dL_U"
      },
      "outputs": [],
      "source": [
        "def custom_information_retrieval():\n",
        "\n",
        "  # Get all docuemnt paths from CMU QA Data sets\n",
        "  print(f\"Creating corpus...\")\n",
        "  document_paths = create_document_paths() #[:5]\n",
        "\n",
        "  # Generate the corpus as a dictionary (note documents are still strings at this point)\n",
        "  corpus = create_corpus(document_paths = document_paths)\n",
        "\n",
        "  # Tokenize documents in corpus\n",
        "  corpus_tokenized = tokenize_corpus(corpus = corpus, tokenizer = custom_tokenizer)\n",
        "  save_as_pickle(object_to_be_saved = corpus_tokenized, file_name = f\"corpus_tokenizedtemp.pickle\")\n",
        "\n",
        "  # Create vocabulary from corpus\n",
        "  print(f\"Creating vocabulary...\")\n",
        "  vocabulary = create_vocabulary(corpus = corpus_tokenized)\n",
        "  save_as_pickle(object_to_be_saved = vocabulary, file_name = f\"vocabulary_temp.pickle\")\n",
        "\n",
        "  # Calculate TF for every document in the corpus\n",
        "  print(f\"Calculating TF for corpus...\")\n",
        "  tf = calculate_term_frequency(corpus = corpus_tokenized, vocabulary = vocabulary)\n",
        "\n",
        "  # Calculate IDF for every document in the corpus\n",
        "  print(f\"Calculating IDF for corpus...\")\n",
        "  idf = calculate_inverse_document_frequency(corpus = corpus_tokenized, vocabulary = vocabulary)\n",
        "\n",
        "  # Calculate the tf-idf for every document in the corpus\n",
        "  print(f\"Calculating TF-IDF for corpus...\")\n",
        "  tfidf = calculate_tfidf( tf = tf, idf = idf)\n",
        "  save_as_pickle(object_to_be_saved = tfidf, file_name = f\"tfidf_temp.pickle\")\n",
        "\n",
        "  # Collect and vectorize all of the input queries\n",
        "  # Columns e.g.  'Question', 'Answer', 'ArticleFileCustom'\n",
        "  print(f\"Calculating Cosine Similarity for all queries accross the corpus...\")\n",
        "  df_queries = df_qa_pairs.copy()\n",
        "  df_queries['MatchingDocuments'] = df_queries[\"Question\"].apply(lambda query: calculate_query_cosine_similarity_for_all_docs(query = query, tfidf = tfidf, vocabulary = vocabulary, tokenizer = custom_tokenizer, n = 5))\n",
        "\n",
        "  return df_queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmdAZoBjdL_U",
        "outputId": "34979d9a-0ec2-4f1b-b356-d7242011a220"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating corpus...\n",
            "Pickle file has been saved to corpus_tokenizedtemp.pickle\n",
            "Creating vocabulary...\n",
            "Pickle file has been saved to vocabulary_temp.pickle\n",
            "Calculating TF for corpus...\n",
            "Calculating IDF for corpus...\n",
            "Calculating TF-IDF for corpus...\n",
            "Pickle file has been saved to tfidf_temp.pickle\n",
            "Calculating Cosine Similarity for all queries accross the corpus...\n"
          ]
        }
      ],
      "source": [
        "df_tfidf = custom_information_retrieval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "S6zRNgpKdL_U",
        "outputId": "ab5f0298-cbdb-4843-a557-1ddfbf7b0fb5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b16f01e7-1b8f-4cdc-8c35-c6c9a985353d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>ArticleTitle</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>DifficultyFromQuestioner</th>\n",
              "      <th>DifficultyFromAnswerer</th>\n",
              "      <th>ArticleFile</th>\n",
              "      <th>ArticleFilesCustom</th>\n",
              "      <th>MatchingDocuments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>S08</td>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Was Abraham Lincoln the sixteenth President of...</td>\n",
              "      <td>yes</td>\n",
              "      <td>easy</td>\n",
              "      <td>easy</td>\n",
              "      <td>data/set3/a4</td>\n",
              "      <td>/content/Question_Answer_Dataset_v1.2/S08/data...</td>\n",
              "      <td>/content/Question_Answer_Dataset_v1.2/S08/data...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>S08</td>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Was Abraham Lincoln the sixteenth President of...</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>easy</td>\n",
              "      <td>easy</td>\n",
              "      <td>data/set3/a4</td>\n",
              "      <td>/content/Question_Answer_Dataset_v1.2/S08/data...</td>\n",
              "      <td>/content/Question_Answer_Dataset_v1.2/S08/data...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>S08</td>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Did Lincoln sign the National Banking Act of 1...</td>\n",
              "      <td>yes</td>\n",
              "      <td>easy</td>\n",
              "      <td>medium</td>\n",
              "      <td>data/set3/a4</td>\n",
              "      <td>/content/Question_Answer_Dataset_v1.2/S08/data...</td>\n",
              "      <td>/content/Question_Answer_Dataset_v1.2/S08/data...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b16f01e7-1b8f-4cdc-8c35-c6c9a985353d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b16f01e7-1b8f-4cdc-8c35-c6c9a985353d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b16f01e7-1b8f-4cdc-8c35-c6c9a985353d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  Dataset     ArticleTitle                                           Question  \\\n",
              "0     S08  Abraham_Lincoln  Was Abraham Lincoln the sixteenth President of...   \n",
              "1     S08  Abraham_Lincoln  Was Abraham Lincoln the sixteenth President of...   \n",
              "2     S08  Abraham_Lincoln  Did Lincoln sign the National Banking Act of 1...   \n",
              "\n",
              "  Answer DifficultyFromQuestioner DifficultyFromAnswerer   ArticleFile  \\\n",
              "0    yes                     easy                   easy  data/set3/a4   \n",
              "1   Yes.                     easy                   easy  data/set3/a4   \n",
              "2    yes                     easy                 medium  data/set3/a4   \n",
              "\n",
              "                                  ArticleFilesCustom  \\\n",
              "0  /content/Question_Answer_Dataset_v1.2/S08/data...   \n",
              "1  /content/Question_Answer_Dataset_v1.2/S08/data...   \n",
              "2  /content/Question_Answer_Dataset_v1.2/S08/data...   \n",
              "\n",
              "                                   MatchingDocuments  \n",
              "0  /content/Question_Answer_Dataset_v1.2/S08/data...  \n",
              "1  /content/Question_Answer_Dataset_v1.2/S08/data...  \n",
              "2  /content/Question_Answer_Dataset_v1.2/S08/data...  "
            ]
          },
          "execution_count": 291,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_tfidf.head(3)\n",
        "# df_tfidf[[\"ArticleTitle\", \"Question\", \"ArticleFileCustom\", \"MatchingDocuments\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4hKdyv2-Ns9"
      },
      "source": [
        "Save the results localy for reloading in the future"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyATG9L8dL_V"
      },
      "outputs": [],
      "source": [
        "df_tfidf.to_csv(\"221003_df_tfidf.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFUKAM8ydL_V"
      },
      "outputs": [],
      "source": [
        "df_tfidf.to_pickle('221003_df_tfidf.pickle')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "aUblSkDdeHtR",
        "outputId": "b01b1059-8bb1-4392-9c09-017c2a961680"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_a9235b66-11ae-4053-b146-c69acdd18223\", \"221003_df_tfidf.pickle\", 1377648)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_7b6af840-09a5-46d8-bcb7-6e0e83dea354\", \"221003_df_tfidf.csv\", 1488936)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/221003_df_tfidf.pickle')\n",
        "files.download('221003_df_tfidf.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7euJbeg-8su"
      },
      "source": [
        "# Create Scoring Metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seueM1lP-8sv"
      },
      "source": [
        "## Validate QA Paths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QPm7czz-8sv"
      },
      "source": [
        "First validate that the custom article paths created from the answers pair files actually match what what is in the corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KJD68rVp-8sv",
        "outputId": "c6cdef64-93f0-449d-8d7d-ee98f8eb6d24"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/Question_Answer_Dataset_v1.2/S08/data/set3/a4.txt'"
            ]
          },
          "execution_count": 310,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_doc_path_from_qa = df_qa_pairs[\"ArticleFilesCustom\"].iloc[0]\n",
        "example_doc_path_from_qa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKsqX0Dk-8sv",
        "outputId": "9ef9535f-e707-4e7a-e5e8-a11a1ffe42ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document: /content/Question_Answer_Dataset_v1.2/S08/data/set3/a4.txt \n",
            "   Found in corpus\n"
          ]
        }
      ],
      "source": [
        "if example_doc_path_from_qa in document_paths:\n",
        "  print(f\"Document: {example_doc_path_from_qa} \\n   Found in corpus\")\n",
        "else:\n",
        "  print(f\"Document {example_doc_path_from_qa} \\n   Not Found in corpus\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FTz_ARc-8sv"
      },
      "source": [
        "Turn this logic into a function and appy to check all the files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFdMm8cD-8sw"
      },
      "outputs": [],
      "source": [
        "def validate_paths_from_questions_answer_pairs_in_corpus(df_qa_pairs: pd.DataFrame, document_paths: list):\n",
        "  \"\"\"\n",
        "  df_qa_pairs = the Question and Answer Pairs from each data set all combined.\n",
        "  document_paths = all the paths collected from the dataset .txt files\n",
        "  \"\"\"\n",
        "  file_paths_matched = 0\n",
        "  file_paths_not_matched = 0\n",
        "  for index, qa_file_path in df_qa_pairs[\"ArticleFilesCustom\"].items():\n",
        "    if qa_file_path in document_paths:\n",
        "      file_paths_matched += 1\n",
        "    elif \",\" in qa_file_path:\n",
        "      sub_file_paths_list = qa_file_path.split(\",\")\n",
        "      for qa_sub_file_path in sub_file_paths_list:\n",
        "        if qa_sub_file_path in document_paths:\n",
        "          pass\n",
        "        else:\n",
        "          file_paths_not_matched += 1\n",
        "          print(f\"File not found: \\n{qa_file_path}\")\n",
        "      file_paths_matched += 1\n",
        "    else:\n",
        "      file_paths_not_matched += 1\n",
        "      print(f\"File not found: \\n{qa_file_path}\")\n",
        "\n",
        "  print(f\"{file_paths_matched} Paths Found \\n{file_paths_not_matched} Paths Not Found\")\n",
        "  return\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-hfiQkw-8sw",
        "outputId": "b417fc9a-a469-41cb-aaa2-344ecbe7fc75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3111 Paths Found \n",
            "0 Paths Not Found\n"
          ]
        }
      ],
      "source": [
        "validate_paths_from_questions_answer_pairs_in_corpus(df_qa_pairs, document_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjwgEtJq-8sw"
      },
      "source": [
        "## Generate Scores for Matching Documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4tGR0F3_O-n"
      },
      "source": [
        "Optionally load the saved dataframe that has already been run the custom information retrieval system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxIF10EP-8sw"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# df_tfidf = pd.read_pickle('220927_df_tfidf.pickle')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G92PGQrEANqO"
      },
      "source": [
        "## Create Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLNxpvhUAWAX"
      },
      "source": [
        "Need to calculate:\n",
        "* Success\n",
        "* Failure\n",
        "* Recall\n",
        "* Precision\n",
        "* F1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiFESsAACqZh"
      },
      "outputs": [],
      "source": [
        "actual_sample = \"\"\"/content/Question_Answer_Dataset_v1.2/S08/data/set4/a1.txt,\\\n",
        "/content/Question_Answer_Dataset_v1.2/S08/data/set4/a4.txt\"\"\"\n",
        "\n",
        "predicted_sample = \"\"\"/content/Question_Answer_Dataset_v1.2/S08/data/set4/a9.txt,\\\n",
        "/content/Question_Answer_Dataset_v1.2/S08/data/set4/a8.txt,\\\n",
        "/content/Question_Answer_Dataset_v1.2/S08/data/set4/a7.txt,\\\n",
        "/content/Question_Answer_Dataset_v1.2/S08/data/set4/a4.txt,\\\n",
        "/content/Question_Answer_Dataset_v1.2/S08/data/set4/a1.txt\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxgdSdDc-twg"
      },
      "outputs": [],
      "source": [
        "def get_true_false_pos_neg(actual: str, predicted: str, corpus_lenght: int = 150 ):\n",
        "  \"\"\"\n",
        "\tTrue Positive (TP) - actual = 1, predicted = 1\n",
        "\tFalse Positive (FP) - actual = 0, predicted = 1\n",
        "\tFalse Negative (FN) - actual = 1, predicted = 0\n",
        "\tTrue Negative (TN) - actual = 0, predicted = 0\n",
        "\t\"\"\"\n",
        "  # Conver the comma separated strings into lists\n",
        "  actual = actual.split(\",\")\n",
        "  predicted = predicted.split(\",\")\n",
        "\n",
        "  # Define the true positives as the numeber of items that are in both the actual\n",
        "  # and the predicted paths\n",
        "  tp = len(set(actual).intersection(predicted))\n",
        "\n",
        "  # Define false positves as the total number of predictions minus what was correct\n",
        "  fp = len(set(predicted)) - tp\n",
        "\n",
        "  # Define the false negatives as 0 since we are not explictle guessing the negative class\n",
        "  fn = 0\n",
        "\n",
        "  # Define the true negatives as the length of the corpus minus the number of guesses\n",
        "  # Rather than pass in the lenght of the \n",
        "  tn = corpus_lenght - len(predicted)\n",
        "\n",
        "  return tp, fp, fn, tn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXzBgor0DjMA",
        "outputId": "3f4487e8-bb5f-4403-e7eb-9e6f1d4dbf46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2 3 0 145\n"
          ]
        }
      ],
      "source": [
        "tp_sample, fp_sample, fn_sample, tn_sample = get_true_false_pos_neg(actual = actual_sample, predicted = predicted_sample)\n",
        "print(tp_sample, fp_sample, fn_sample, tn_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qjHBhmwo-1w"
      },
      "source": [
        "Calculate success of predicted documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iHDb9fDpM4X"
      },
      "outputs": [],
      "source": [
        "def calculate_success(actual: str, predicted: str):\n",
        "  # Calculate if the documnet path answers were correctly predicted\n",
        "  # Compare the number of the correctly predicted answers to the number of correct\n",
        "  # answers provided for a given query\n",
        "\n",
        "  # Conver the comma separated strings into lists\n",
        "  actual = actual.split(\",\")\n",
        "  predicted = predicted.split(\",\")\n",
        "\n",
        "  success = 0\n",
        "  fail = 0\n",
        "\n",
        "  if len(set(actual).intersection(predicted)) == len(actual):\n",
        "    success = 1\n",
        "  else:\n",
        "    fail = 1\n",
        "\n",
        "  return success, fail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ivo5siFqaog",
        "outputId": "9df7731c-9500-481d-c016-dc28b8c60c41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 0)"
            ]
          },
          "execution_count": 319,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "success_sample, fail_sample = calculate_success(actual = actual_sample, predicted = predicted_sample)\n",
        "success_sample, fail_sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "359arHL0lmfg"
      },
      "source": [
        "Calculate precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Cle-6IBlsW_"
      },
      "outputs": [],
      "source": [
        "def calculate_precision(tp: int, fp: int):\n",
        "  # Precision = TP / (TP + FP)\n",
        "  precision = tp / (tp + fp)\n",
        "  return precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z-ixmBxlsUZ",
        "outputId": "18d43830-5dce-4f05-cbc3-6b43a8d46dce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.4"
            ]
          },
          "execution_count": 321,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "precision_sample = calculate_precision(tp = tp_sample, fp = fp_sample)\n",
        "precision_sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGL3B105mcWP"
      },
      "source": [
        "Calculate recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLY3qj78mej9"
      },
      "outputs": [],
      "source": [
        "def calculate_recall(tp: int, fn: int):\n",
        "  # Recall = TP / (TP + FN)\n",
        "  try:\n",
        "    recall = tp / (tp + fn)\n",
        "  except:\n",
        "    recall = 0.0\n",
        "  return recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bkr22xmamee-",
        "outputId": "0fb7d22c-f8da-4e2f-8bef-0fd262fa6902"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 323,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "recall_sample = calculate_recall(tp = tp_sample, fn = fn_sample)\n",
        "recall_sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOraaae3m4QB"
      },
      "source": [
        "Calculate F1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nas-7XZEm4D6"
      },
      "outputs": [],
      "source": [
        "def calculate_f1(precision: float, recall :float):\n",
        "  # Calculate the F1 score where F1 = 2* (precision * recall) / (precision + recall)\n",
        "  try:\n",
        "    f1 = 2* (precision * recall) / (precision + recall)\n",
        "  except:\n",
        "    f1 = 0.0\n",
        "  return f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8ilpoKBm4Bn",
        "outputId": "24a33bb4-8c11-47df-ed91-f0c42d86ea4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5714285714285715"
            ]
          },
          "execution_count": 325,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f1_sample = calculate_f1(precision = precision_sample, recall = recall_sample)\n",
        "f1_sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ic8v_0qrAfq"
      },
      "source": [
        "## Apply Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U22MV9MZrLXG"
      },
      "source": [
        "Next, apply the custom metrics to the out put of the information retrieval system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onlddN3MbGNi",
        "outputId": "0d1ef3b6-97f7-4b9f-d01f-dfab0872a380"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Dataset', 'ArticleTitle', 'Question', 'Answer',\n",
              "       'DifficultyFromQuestioner', 'DifficultyFromAnswerer', 'ArticleFile',\n",
              "       'ArticleFilesCustom'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 326,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_qa_pairs.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbIqxbilm37n"
      },
      "outputs": [],
      "source": [
        "def apply_custom_metrics_to_df(df: pd.DataFrame, actuals_col_name: str = 'ArticleFilesCustom', predicted_col_name: str = 'MatchingDocuments'):\n",
        "  # Make a copy of the input dataframe\n",
        "  df_original = df.copy()\n",
        "\n",
        "  # Calculate True and False Positves and Negatives\n",
        "  df_true_false_pos_neg = df_original.apply(lambda row: get_true_false_pos_neg(actual = row[actuals_col_name], predicted = row[predicted_col_name]), axis='columns', result_type='expand')\n",
        "  df_true_false_pos_neg.columns = ['tp', 'fp', 'fn', 'tn']\n",
        "  df_metrics = pd.concat([df_original, df_true_false_pos_neg], axis='columns')\n",
        "\n",
        "  # Calculate Success\n",
        "  df_success = df_metrics.apply(lambda row: calculate_success(actual = row[actuals_col_name], predicted = row[predicted_col_name]), axis='columns', result_type='expand')\n",
        "  df_success.columns = ['success', 'fail']\n",
        "  df_metrics = pd.concat([df_metrics, df_success], axis='columns')\n",
        "\n",
        "  # Calculate Precision\n",
        "  df_precision = df_metrics.apply(lambda row: calculate_precision(tp = row['tp'], fp = row['fp']), axis='columns', result_type='expand')\n",
        "  df_metrics['precision'] = df_precision\n",
        "\n",
        "  # Calculate Recall\n",
        "  df_recall = df_metrics.apply(lambda row: calculate_recall(tp = row['tp'], fn = row['fn']), axis='columns', result_type='expand')\n",
        "  df_metrics['recall'] = df_recall\n",
        "\n",
        "  # Calculate F1\n",
        "  df_f1 = df_metrics.apply(lambda row: calculate_f1(precision = row['precision'], recall = row['recall']), axis='columns', result_type='expand')\n",
        "  df_metrics['f1'] = df_f1\n",
        "\n",
        "  return df_metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp2JNX6Un39Z"
      },
      "source": [
        "Apply the custom metrics to the Information Retrieval System Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "No0IWWMGbCfN",
        "outputId": "1de09a4e-7204-48c6-c44d-aacbb36f2178"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-79a93f55-59ea-4df3-bd75-ef27b6330d75\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>ArticleTitle</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>DifficultyFromQuestioner</th>\n",
              "      <th>DifficultyFromAnswerer</th>\n",
              "      <th>ArticleFile</th>\n",
              "      <th>ArticleFilesCustom</th>\n",
              "      <th>MatchingDocuments</th>\n",
              "      <th>tp</th>\n",
              "      <th>fp</th>\n",
              "      <th>fn</th>\n",
              "      <th>tn</th>\n",
              "      <th>success</th>\n",
              "      <th>fail</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>S08</td>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Was Abraham Lincoln the sixteenth President of...</td>\n",
              "      <td>yes</td>\n",
              "      <td>easy</td>\n",
              "      <td>easy</td>\n",
              "      <td>data/set3/a4</td>\n",
              "      <td>/content/Question_Answer_Dataset_v1.2/S08/data...</td>\n",
              "      <td>/content/Question_Answer_Dataset_v1.2/S08/data...</td>\n",
              "      <td>1</td>\n",
              "      <td>149</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.006667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.013245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>S08</td>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Was Abraham Lincoln the sixteenth President of...</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>easy</td>\n",
              "      <td>easy</td>\n",
              "      <td>data/set3/a4</td>\n",
              "      <td>/content/Question_Answer_Dataset_v1.2/S08/data...</td>\n",
              "      <td>/content/Question_Answer_Dataset_v1.2/S08/data...</td>\n",
              "      <td>1</td>\n",
              "      <td>149</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.006667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.013245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>S08</td>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Did Lincoln sign the National Banking Act of 1...</td>\n",
              "      <td>yes</td>\n",
              "      <td>easy</td>\n",
              "      <td>medium</td>\n",
              "      <td>data/set3/a4</td>\n",
              "      <td>/content/Question_Answer_Dataset_v1.2/S08/data...</td>\n",
              "      <td>/content/Question_Answer_Dataset_v1.2/S08/data...</td>\n",
              "      <td>1</td>\n",
              "      <td>149</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.006667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.013245</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79a93f55-59ea-4df3-bd75-ef27b6330d75')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-79a93f55-59ea-4df3-bd75-ef27b6330d75 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-79a93f55-59ea-4df3-bd75-ef27b6330d75');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  Dataset     ArticleTitle                                           Question  \\\n",
              "0     S08  Abraham_Lincoln  Was Abraham Lincoln the sixteenth President of...   \n",
              "1     S08  Abraham_Lincoln  Was Abraham Lincoln the sixteenth President of...   \n",
              "2     S08  Abraham_Lincoln  Did Lincoln sign the National Banking Act of 1...   \n",
              "\n",
              "  Answer DifficultyFromQuestioner DifficultyFromAnswerer   ArticleFile  \\\n",
              "0    yes                     easy                   easy  data/set3/a4   \n",
              "1   Yes.                     easy                   easy  data/set3/a4   \n",
              "2    yes                     easy                 medium  data/set3/a4   \n",
              "\n",
              "                                  ArticleFilesCustom  \\\n",
              "0  /content/Question_Answer_Dataset_v1.2/S08/data...   \n",
              "1  /content/Question_Answer_Dataset_v1.2/S08/data...   \n",
              "2  /content/Question_Answer_Dataset_v1.2/S08/data...   \n",
              "\n",
              "                                   MatchingDocuments  tp   fp  fn  tn  \\\n",
              "0  /content/Question_Answer_Dataset_v1.2/S08/data...   1  149   0   0   \n",
              "1  /content/Question_Answer_Dataset_v1.2/S08/data...   1  149   0   0   \n",
              "2  /content/Question_Answer_Dataset_v1.2/S08/data...   1  149   0   0   \n",
              "\n",
              "   success  fail  precision  recall        f1  \n",
              "0        1     0   0.006667     1.0  0.013245  \n",
              "1        1     0   0.006667     1.0  0.013245  \n",
              "2        1     0   0.006667     1.0  0.013245  "
            ]
          },
          "execution_count": 328,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_tfidf_with_metrics = apply_custom_metrics_to_df(df = df_tfidf, actuals_col_name = 'ArticleFilesCustom', predicted_col_name = 'MatchingDocuments')\n",
        "df_tfidf_with_metrics.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_5PdQ2ETKcp"
      },
      "outputs": [],
      "source": [
        "# df_tfidf_with_metrics.to_csv('221005_df_tfidf_with_metrics.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZimNNhRn_ux"
      },
      "source": [
        "Calculate the summary metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OEqBGY0boFh"
      },
      "outputs": [],
      "source": [
        "def summary_metrics(df_with_metrics: pd.DataFrame):\n",
        "  df = df_with_metrics.copy()\n",
        "\n",
        "  # Success\n",
        "  success = df['success'].sum()\n",
        "\n",
        "  # Fail\n",
        "  fail = df['fail'].sum()\n",
        "\n",
        "  # Precision\n",
        "  precision = df['precision'].mean()\n",
        "\n",
        "  # Recall\n",
        "  recall = df['recall'].mean()\n",
        "\n",
        "  # F1\n",
        "  f1 = df['f1'].mean()\n",
        "\n",
        "  return success, fail, precision, recall, f1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYZjeI7sboDG",
        "outputId": "1f17112c-149c-49b4-b9cb-0e9f2f2af9d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3111, 0, 0.006694524804457302, 1.0, 0.013299652152343092)"
            ]
          },
          "execution_count": 330,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary_metrics(df_with_metrics = df_tfidf_with_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYBxuptWqMX8"
      },
      "source": [
        "TODO:\n",
        "\n",
        "Create formatted output that passes the grading criteria\n",
        "\n",
        "```\n",
        "Success | # | failure | # \n",
        "Recall | # \n",
        "Precision | # \n",
        "F1 | #\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hE4dBtvqVokZ"
      },
      "outputs": [],
      "source": [
        "def create_metrics_output_file(success: float, fail: float, precision: float, recall: float, f1: float) -> str:\n",
        "  content = f\"\"\"Success|{success}|Failure|{fail}\\navg recall|{recall}\\navg precision|{precision}\\navg F1|{f1}\"\"\"\n",
        "  return content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5A_Uu74WM9g"
      },
      "outputs": [],
      "source": [
        "metrics_message = create_metrics_output_file(*summary_metrics(df_with_metrics = df_tfidf_with_metrics))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcEhFeNBboAn",
        "outputId": "793c62be-f235-4a6c-96ce-ff9622def626"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Success|3111|Failure|0\n",
            "avg recall|1.0\n",
            "avg precision|0.006694524804457302\n",
            "avg F1|0.013299652152343092\n"
          ]
        }
      ],
      "source": [
        "# Open the file in the write mode\n",
        "with open('test_csv_write.csv', 'w') as f:\n",
        "    # create the csv writer\n",
        "    print(metrics_message)\n",
        "    f.write(metrics_message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpRrvumUYhEZ"
      },
      "source": [
        "Run the validator to endure file format works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vdx53dtYYlQG",
        "outputId": "77b149a3-96e1-4011-f651-54b76bb45e7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Format all good\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import sys\n",
        "from os.path import exists\n",
        "from pathlib import Path\n",
        "\n",
        "metrics_file_path = \"/content/test_csv_write.csv\"\n",
        "\n",
        "with open(metrics_file_path, newline='\\n') as csvfile: #sys.argv[1]\n",
        "    spamreader = csv.reader(csvfile, delimiter='|', quotechar='\"')\n",
        "    inQuestion = False\n",
        "    succFailLabels = False\n",
        "    hasRecall = False\n",
        "    hasPrec = False\n",
        "    hasF1 = False\n",
        "    count = 0\n",
        "    for row in spamreader:\n",
        "      if (not row and count > 0):\n",
        "        print(\"Error: row \", count, \" is empty\")\n",
        "      if (len(row) == 1):\n",
        "        inQuestion = True\n",
        "      if (len(row) == 2 and row[0] == \"\"):\n",
        "        if (not exists(Path(row[1].strip()))):\n",
        "            print(\"Error: file \", row[1], \" does not exist\")\n",
        "      if (len(row) == 4):\n",
        "        if (row[0].strip() != \"Success\" or row[2].strip() != \"Failure\"):\n",
        "            print(\"bad labels in \", row)\n",
        "        else:\n",
        "            succFailLabels = True\n",
        "      if (len(row) == 2 and row[0].startswith(\"avg\")):\n",
        "        if (row[0].strip() == \"avg recall\"):\n",
        "            hasRecall = True\n",
        "        elif (row[0].strip() == \"avg precision\"):\n",
        "            hasPrec = True\n",
        "        elif (row[0].strip() == \"avg F1\"):\n",
        "            hasF1 = True\n",
        "        else:\n",
        "            print(\"bad row: \", row)\n",
        "            row = row + 1\n",
        "    if (not hasRecall or not hasPrec or not hasF1):\n",
        "      print(\"Missing metrics\")\n",
        "    else:\n",
        "      print(\"Format all good\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kcyk62fSYlLX"
      },
      "outputs": [],
      "source": [
        "# "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctnwMrPxdL_W"
      },
      "source": [
        "# TODO: This Part"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmzJSQ0IemCA"
      },
      "source": [
        "TODO:\n",
        "* Figure out a format for combining multiple correct files into one line\n",
        "* Figure out how to conver the 5 predicted paths and find out the set() between them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqbK3vy_DjJk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lzk3VFEJ-trM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wn06sWII-tpF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIhrb_QL-tnL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbBLRObP-tkn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDY9K7Nz-th_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwolgft7-tfL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxiIKYrrkzfl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7quA-1TXUGQG"
      },
      "source": [
        "# Reference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijhvbKUFUI-1"
      },
      "source": [
        "Good Kaggle areticle for the Question and Answer part.\n",
        "\n",
        "[https://www.kaggle.com/code/francispimentel/finding-the-closest-question-and-then-anwering-it](https://www.kaggle.com/code/francispimentel/finding-the-closest-question-and-then-anwering-it)\n",
        "\n",
        "See tutorial on Information Retreval [Information Retrieval](https://github.com/LearnPythonWithRune/MachineLearningWithPython/blob/main/colab/final/13%20-%20Project%20-%20Information%20Retrieval%20(IR).ipynb)\n",
        "\n",
        "Youtube Tutorial on Information Retrieval [Video](https://www.youtube.com/watch?v=OUYioG0cydI&ab_channel=LearnPythonwithRune)\n",
        "\n",
        "Nice example of TF-IDF and cosine similarity [Article](https://courses.cs.washington.edu/courses/cse373/17au/project3/project3-2.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SI7TiyW3UIhq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDaRoKpIUHxM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "information_retrieval",
      "language": "python",
      "name": "information_retrieval"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
